 Starting training with config: {'wandb_project': 'da6401_a1', 'wandb_entity': 'da24m002-indian-institute-of-technology-madras', 'dataset': 'fashion_mnist', 'epochs': 20, 'batch_size': 64, 'loss': 'cross_entropy', 'optimizer': 'nadam', 'learning_rate': 0.001, 'momentum': 0.9, 'beta': 0.9, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08, 'weight_decay': 0.0, 'weight_init': 'Xavier', 'num_layers': 4, 'hidden_size': 128, 'activation': 'sigmoid', 'sweep': False}
Epoch 1/1 - loss: 0.8945 - accuracy: 0.6865 - val_loss: 0.5357 - val_accuracy: 0.8283
Test loss: 0.5566 - Test accuracy: 0.8175
Training completed! Best parameters used:
- Model: 4 hidden layers with 128 neurons each
- Activation: sigmoid
- Optimizer: nadam
- Learning rate: 0.001
- Weight initialization: Xavier
- Confusion matrix saved to confusion_matrix_enhanced.png
